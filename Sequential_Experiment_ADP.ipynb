{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef93385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import itertools\n",
    "import random\n",
    "import scipy.integrate\n",
    "import scipy.stats\n",
    "from sklearn import linear_model\n",
    "################################\n",
    "from helper_functions import z_expectation_variance, KMS_Matrix, product_diff_list, moment_matching_update, g_fun, g_fun_linear_regression, question_selection_prob, g_opt, two_step_g_acq, question_extractor, rollout,monte_carlo_rollout, batch_design_delta_penalty, coordinate_exchange_acq, enum_two_step, enum_two_step_opt, rollout_with_batch_design_acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cafa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to compare different methods in a sequential fashion using normalized MSE, determinant, \n",
    "#hitrate, and MSE as a measurement \n",
    "#of quality. In this function, we only use one acquisition method at a time.\n",
    "\n",
    "def new_sequential_experiment(init_mu, init_Sig, true_partworths, rep_per_partworth, num_questions,look_ahead_horizon, mu_log_coeff,\n",
    "                                   Sig_log_coeff,noise_par, question_list, Method = 0,\n",
    "                                   batch_size = 0, MC_budget = 0, include_one_step = False,penalty = 100,rel_gap = 0.0001):\n",
    "    #init_mu: This is the initial estimate on the partworths\n",
    "    #init_Sig: This is the initial covariance matrix on the partworths\n",
    "    #true_partworths: These are used to make selection in the product selection stage (a list/set of partworths)\n",
    "    #rep_per_partworth: This is the number of times we want to conduct a questionnaire on each partworth\n",
    "    #num_questions: Length of the questionnaire\n",
    "    #look_ahead_horizon: This is the number of stages that we look ahead in a rollout method.\n",
    "    #mu_log_coeff; Sig_log_coeff: These are the coefficients in the optimization model for the linearized objective function\n",
    "    #noise_par: This is a parameter which is used to increase the weight of the individuals' true partworth when making decision\n",
    "    #question_list: This is a list of questions which will be used to calculate the hitrate, which is the\n",
    "    #proportion of times that an estimated partworth matches the product selection of a true underlying partworth.\n",
    "    #between x and y. The higher this weight is, the less effect the gumbel random variable has on user choice.\n",
    "    #Method: 0 - One step look ahead\n",
    "    #        1 - Rollout with batch design   <------ CAN ADD MORE METHODS IF NEEDED\n",
    "    #        2 - Two step look ahead via enumeration\n",
    "    #        3 - Rollout using coordinate exchange\n",
    "    #batch_size: Used to select batch size if we use rollout\n",
    "    #        OPTIONS:\n",
    "    #        batch_size = n (n is a non-negative integer): This will make it so that the batch size is constant and equal to n for every rollout iteration\n",
    "    #        batch_size = -1: This will make it so that the batch size is equal to the look-ahead horizon\n",
    "    #MC_budget: Used to select Monte Carlo budget if we use rollout.\n",
    "    #include_one_step: This determines whether we want to include the one-step optimal question within our batch. This can\n",
    "    #help ensure that rollout performs at least as well as one-step look ahead. Default value is False.\n",
    "    #penalty_term: This is used to set the penalty level for orthogonality in the orthogonal batch design optimization problem. A higher penalty\n",
    "    #term will lead to a more Sigma_orthogonal design, while a lower penalty term will lead to less Sigma_orthogonality in the design\n",
    "    #rel_gap: This is used in rollout with coordinate exchange. This value measures the improvement of a question's rollout\n",
    "    #value over the current question's rollout value. If the improvement is greater than the relative gap, we update the current\n",
    "    #question\n",
    "    \n",
    "    \n",
    "    #Construct lists for storing normalized MSE, determinant, hitrate, and MSE information. \n",
    "    #For each of the baseline partworths, we create a list holding\n",
    "    #(num_questions) lists, where each of the (num_questions) lists holds the MSE and determinant values for all replications\n",
    "    #after the first, second,...,nth question\n",
    "    \n",
    "    num_true_partworth = len(true_partworths) \n",
    "    \n",
    "    hitrate_total_num_of_questions = len(question_list)\n",
    "    \n",
    "    \n",
    "    #Construct the expected preferred product selection for each true partworth. This will be used when we calculate the probability\n",
    "    #of correct selection\n",
    "    x_trueselection = [[] for u in range(num_true_partworth)]\n",
    "    attributes_num = len(init_mu)\n",
    "    for u in range(num_true_partworth):\n",
    "        x_trueselection[u] = np.array([1.0 if partworth_component>=0.0 else 0.0 for partworth_component in \n",
    "                                           true_partworths[u]])\n",
    "    \n",
    "    #Set up lists to hold normalized MSE, determinant, MSE, and hitrate information. For now, we will only calculate hitrate at the end\n",
    "    #of the questionnaire. Also save the mu vectors. \n",
    "    \n",
    "    MSE_normalized = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    DET = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    HITRATE = [[] for u in range(num_true_partworth)]\n",
    "    \n",
    "    MSE = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    PROB_CORRECT_SEL = []\n",
    "    \n",
    "    MU = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    for u in range(num_true_partworth):\n",
    "        #create a variable which will store the number of correct selections.\n",
    "        correct_sel = 0\n",
    "        for i in range(rep_per_partworth):\n",
    "            #Instantiate mu and Sig with the initial parameters init_mu and init_Sig. These act as prior parameters for all\n",
    "            #the partworths\n",
    "            mu = init_mu\n",
    "            Sig = init_Sig\n",
    "            for j in range(num_questions):\n",
    "                if Method == 0:\n",
    "                    #get optimal question for one step\n",
    "                    [x,y] = g_opt(mu,Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "                    \n",
    "                if Method == 1:\n",
    "                    #get optimal question for rollout over batch design\n",
    "                    #Use a rollout length equal to look_ahead_horizon - 1, until we are within look_ahead_horizon of the\n",
    "                    #budget\n",
    "                    \n",
    "                    if j < num_questions - look_ahead_horizon:\n",
    "                        rollout_len = look_ahead_horizon - 1\n",
    "                    else:\n",
    "                        rollout_len = num_questions - j - 1\n",
    "                    \n",
    "                    if batch_size == -1:\n",
    "                        #When batch_size is -1, we use the rollout length + 1 as the batch size.\n",
    "                        [x,y] = rollout_with_batch_design_acquisition(mu,Sig,mu_log_coeff,Sig_log_coeff,rollout_len+1,\n",
    "                                                                 rollout_len,MC_budget,include_one_step,penalty_term = penalty)\n",
    "                    else:\n",
    "                        [x,y] = rollout_with_batch_design_acquisition(mu,Sig,mu_log_coeff,Sig_log_coeff,batch_size,\n",
    "                                                                 rollout_len,MC_budget,include_one_step,penalty_term = penalty)\n",
    "                    \n",
    "                if Method == 2:\n",
    "                    #Do the enumeration procedure for two-step look ahead\n",
    "                    if j < num_questions-1:\n",
    "                        enumerated_solution_list_two_step = enum_two_step(mu,Sig,mu_log_coeff,\n",
    "                                                             Sig_log_coeff,question_list)\n",
    "                        opt_sol_questions_two_step = enum_two_step_opt(enumerated_solution_list_two_step[0],\n",
    "                                                          enumerated_solution_list_two_step[2])\n",
    "                    \n",
    "                        #get the first stage products for true two-step\n",
    "                        x = np.array(opt_sol_questions_two_step[1])\n",
    "                        y = np.array(opt_sol_questions_two_step[2])\n",
    "                    #Use one-step for the last question.\n",
    "                    else:\n",
    "                        [x,y] = g_opt(mu,Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "                    \n",
    "                if Method == 3:\n",
    "                    #Do rollout with coordinate exchange\n",
    "                    if j < num_questions - look_ahead_horizon:\n",
    "                        rollout_len = look_ahead_horizon - 1\n",
    "                    else:\n",
    "                        rollout_len = num_questions - j - 1\n",
    "                        \n",
    "                    [x,y] = coordinate_exchange_acq(mu,Sig,mu_log_coeff,Sig_log_coeff,batch_size,rollout_len,\n",
    "                                                   MC_budget,rel_gap,include_batch = False,include_one_step = True)\n",
    "                \n",
    "                #!!!WE WILL NOT USE GUMBEL RANDOM VARIABLE IN TYPE II EXPERIMENT!!!\n",
    "                #Instantiate gumbel random variables which are used in the product choice selection process.\n",
    "                #gum_x = rng.gumbel(0,1,1)\n",
    "                #gum_y = rng.gumbel(0,1,1)\n",
    "                    \n",
    "                #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "                x_temp = x\n",
    "                y_temp = y\n",
    "                    \n",
    "                #See preference between two products\n",
    "                #set signal to noise ratio\n",
    "                if (noise_par*np.dot(true_partworths[u],np.array(y))) >= (noise_par*np.dot(true_partworths[u],np.array(x))):\n",
    "                    x = y_temp\n",
    "                    y = x_temp\n",
    "                \n",
    "                #Perform moment matching after choice is made.\n",
    "                [mu, Sig] = moment_matching_update(x,y,mu,Sig)\n",
    "                \n",
    "                #add mu to the list of mu vectors\n",
    "                MU[u][j].append(mu)\n",
    "                #Add the normalized MSE between the true partworth and estimator at question j to a list, and add the determinant of\n",
    "                #the covariance matrix at question j into a list. Also add the regular MSE\n",
    "                MSE_normalized[u][j].append(np.square(np.subtract(true_partworths[u]/np.linalg.norm(true_partworths[u],ord = 2),\n",
    "                                                            mu/np.linalg.norm(mu, ord = 2))).mean())\n",
    "                DET[u][j].append(np.linalg.det(Sig))\n",
    "                \n",
    "                MSE[u][j].append(np.square(np.subtract(true_partworths[u],\n",
    "                                                            mu)).mean())\n",
    "                \n",
    "            #Calculate hitrate for this replication. Given a set of questions of length K, we compare how well the final \n",
    "            #estimator performs in terms of correctly selecting the preferred profile for each question. The estimator\n",
    "            #makes a correct selection if its selection matches that of the true partworth (selection is absent of gumble noise)\n",
    "            hits = 0\n",
    "            for q in question_list:\n",
    "                if np.dot(true_partworths[u],q)*np.dot(mu,q)>=0:\n",
    "                    hits = hits + 1\n",
    "            HITRATE[u].append(hits/hitrate_total_num_of_questions)\n",
    "            \n",
    "            #Calculate whether we have correct selection in this replication for estimator mu\n",
    "            x_mu = np.array([1.0 if mu_component>=0.0 else 0.0 for mu_component in \n",
    "                                           mu])\n",
    "            if np.dot(x_trueselection[u]-x_mu,x_trueselection[u]-x_mu) == 0.0:\n",
    "                correct_sel = correct_sel + 1\n",
    "                \n",
    "        \n",
    "        #Calculate the probability of correct selection for the current true partworth\n",
    "        PROB_CORRECT_SEL.append(correct_sel/rep_per_partworth)\n",
    "                \n",
    "        \n",
    "    return[MSE_normalized,DET,HITRATE,MSE,PROB_CORRECT_SEL,true_partworths,MU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78528cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to define the experimental setting that will be used in the sequential experiment. The experimental \n",
    "#settings are found in the LaTex document \"Bayesian Sequential Preference Learning Experimental Settings\"\n",
    "def experiment_settings(attr,bp_exp,bp_cov,signal_noise,look_ahead,ortho_pen):\n",
    "    #attr: The number of attributes of a product. Note that the rest of the \n",
    "        #1 : 6 attributes\n",
    "        #2 : 12 attributes\n",
    "    #bp_exp: This is the type of bayesian prior expectation we start with\n",
    "        #1 : homogeneous\n",
    "        #2 : heterogeneous\n",
    "    #bp_cov: This the the type of bayesian prior covariance we start with\n",
    "        #1 : homogeneous diagonal\n",
    "        #2 : heterogeneous diagonal\n",
    "        #3 : non-diagonal\n",
    "    #signal_noise_ratio: This is the signal to noise ratio between the expectation and covariance.\n",
    "        #1 : Low = 0.25\n",
    "        #2 : Normal = 1.0\n",
    "        #3 : High = 4.0\n",
    "    #look_ahead: This is the look ahead horizon that we will use\n",
    "        #1 : 1/3 of the number of attributes\n",
    "        #2 : 2/3 of the number of attributes\n",
    "        #3 : Equal to the number of attributes\n",
    "    #ortho_pen: This is the parameter which penalizes the orthogonality condition in the orthogonal batch design\n",
    "        #1 : small = 0.01\n",
    "        #2 : large = 10.0\n",
    "    \n",
    "    \n",
    "    if attr == 1:\n",
    "        #Define number of attributes\n",
    "        attributes = 6\n",
    "        \n",
    "        #define bayesian prior parameters\n",
    "        if bp_exp == 1:\n",
    "            bayes_expectation = np.array(attributes*[1.0])\n",
    "        if bp_exp == 2:\n",
    "            bayes_expectation = np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        \n",
    "        \n",
    "        if bp_cov == 1:\n",
    "            bayes_covariance = np.identity(attributes)\n",
    "        if bp_cov == 2:\n",
    "            bayes_covariance = np.diag([2.0,1/2,4.0,1/4,8.0,1/8])\n",
    "        if bp_cov == 3:\n",
    "            bayes_covariance = 1.25*KMS_Matrix(attributes,-0.5)\n",
    "        \n",
    "        if look_ahead == 1:\n",
    "            look_ahead_horizon = 2\n",
    "        if look_ahead == 2:\n",
    "            look_ahead_horizon = 4\n",
    "        if look_ahead == 3:\n",
    "            look_ahead_horizon = 6\n",
    "        \n",
    "        #calculate coefficient parameters for optimization problem\n",
    "        mu_log,Sig_log = g_fun_linear_regression(0,12.70,0.1,42.0,24,84)\n",
    "        \n",
    "        #Create a list of questions\n",
    "        question_list = product_diff_list(attributes)\n",
    "        \n",
    "    if attr == 2:\n",
    "        #Define number of attributes\n",
    "        attributes = 12\n",
    "        \n",
    "        #Define bayesian prior parameters\n",
    "        if bp_exp == 1:\n",
    "            bayes_expectation = np.array(attributes*[1.0])\n",
    "        if bp_exp == 2:\n",
    "            bayes_expectation = np.array([-0.125,0.25,-0.375,0.5,-0.625,0.75,-0.875,1.0,\n",
    "                                         -1.125,1.25,-1.375,1.5])\n",
    "        \n",
    "        if bp_cov == 1:\n",
    "            bayes_covariance = np.identity(attributes)\n",
    "        if bp_cov == 2:\n",
    "            bayes_covariance = np.diag([2.0,1/2,3.0,1/3,4.0,1/4,16/3,3/16,20/3,\n",
    "                                       3/20,8,1/8])\n",
    "        if bp_cov == 3:\n",
    "            bayes_covariance = 1.25*KMS_Matrix(attributes,-0.5)\n",
    "        \n",
    "        if look_ahead == 1:\n",
    "            look_ahead_horizon = 4\n",
    "        if look_ahead == 2:\n",
    "            look_ahead_horizon = 8\n",
    "        if look_ahead == 3:\n",
    "            look_ahead_horizon = 12\n",
    "        \n",
    "        #calculate coefficient parameters for optimization problem\n",
    "        mu_log,Sig_log = g_fun_linear_regression(0, 24.50, 0.1, 156.0, 49, 312)\n",
    "        \n",
    "        #Create a list of questions, take a random sample of 3^6 since there are around 3^12 possibilities\n",
    "        question_list = product_diff_list(attributes)\n",
    "    \n",
    "        question_list = random.sample(question_list,3**6)\n",
    "    \n",
    "    #Set up signal to noise ratio\n",
    "    if signal_noise == 1:\n",
    "        signal_noise_ratio = 0.25\n",
    "    if signal_noise == 2:\n",
    "        signal_noise_ratio = 1.0\n",
    "    if signal_noise == 3:\n",
    "        signal_noise_ratio = 4.0\n",
    "        \n",
    "    #Set up orthogonality parameter\n",
    "    if ortho_pen == 1:\n",
    "        orthogonality_penalty_parameter = 0.01\n",
    "    if ortho_pen == 2:\n",
    "        orthogonality_penalty_parameter = 10.0\n",
    "    \n",
    "    #Scale the bayes expectation by the signal to noise ratio   \n",
    "    bayes_scale_expectation = signal_noise_ratio*bayes_expectation\n",
    "    \n",
    "    return[attributes,bayes_scale_expectation,bayes_covariance,look_ahead_horizon,\n",
    "          orthogonality_penalty_parameter,mu_log,Sig_log,question_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88858db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up some parameters. \n",
    "\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "#EXPERIMENT SETTING ARGUMENTS\n",
    "attr_exp = int(sys.argv[1])\n",
    "bp_expect_exp = int(sys.argv[2])\n",
    "bp_cov_exp = int(sys.argv[3])\n",
    "signal_noise_exp = int(sys.argv[4])\n",
    "look_ahead_exp = int(sys.argv[5])\n",
    "ortho_pen_exp = int(sys.argv[6])\n",
    "\n",
    "\n",
    "#We need a way to read in the arguments for experiment_settings (for job arrays)\n",
    "[attributes_exp,bayes_expectation_exp,bayes_covariance_exp,look_ahead_horizon_exp,orthogonality_penalty_parameter_exp,\n",
    "mu_log_exp,Sig_log_exp,question_list_exp] = experiment_settings(attr_exp,bp_expect_exp,bp_cov_exp,signal_noise_exp,\n",
    "                                                               look_ahead_exp,ortho_pen_exp)\n",
    "\n",
    "#print([bayes_expectation_exp,bayes_covariance_exp,look_ahead_horizon_exp,orthogonality_penalty_parameter_exp,\n",
    "#mu_log_exp,Sig_log_exp,question_list_exp])\n",
    "#Create list of true partworths. This will have the property that one is close to the initial estimator, and one is \n",
    "#far away\n",
    "samp_num_partworths = 100\n",
    "\n",
    "#Create a list of random partworths\n",
    "partworths_exp = []\n",
    "\n",
    "for i in range(0,samp_num_partworths):\n",
    "        partworths_exp.append(rng.multivariate_normal(bayes_expectation_exp,bayes_covariance_exp))\n",
    "\n",
    "#!!!WE DO NOT USE THE MAX AND MIN MSE VECTORS!!!\n",
    "#Use only the two partworths with the max and min MSE compared to the initial parameter estimator.\n",
    "#init_mse_values = samp_num_partworths*[0.0]\n",
    "#for i in range(0,samp_num_partworths):\n",
    "    #init_mse_values[i] =  np.square(np.subtract(partworths_exp[i]/np.linalg.norm(partworths_exp[i],ord = 2),\n",
    "                                                            #bayes_expectation_exp/np.linalg.norm(bayes_expectation_exp, ord = 2))).mean()\n",
    "#init_mse_max_index = np.argmax(np.array(init_mse_values))\n",
    "#init_mse_min_index = np.argmin(np.array(init_mse_values))\n",
    "#partworths_exp = [partworths_exp[init_mse_min_index],partworths_exp[init_mse_max_index]]\n",
    "\n",
    "#repetition per partworth\n",
    "rep_per_partworth_exp = 1\n",
    "\n",
    "#number of questions\n",
    "num_questions_exp = 16\n",
    "\n",
    "#noise parameter in selection process\n",
    "noise_par_exp = 1.0\n",
    "\n",
    "#batch size\n",
    "batch_size_exp = -1\n",
    "\n",
    "#Monte Carlo sampling budget\n",
    "MC_budget_exp = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONESTEP\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_OS,DET_OS,HITRATE_OS,MSE_OS,Prob_sel_OS,true_partworths_OS,MU_OS] = new_sequential_experiment(bayes_expectation_exp,bayes_covariance_exp,partworths_exp,rep_per_partworth_exp,num_questions_exp,\n",
    "                                           look_ahead_horizon_exp,mu_log_exp,Sig_log_exp,noise_par_exp,question_list_exp,Method = 0,\n",
    "                                            batch_size = batch_size_exp,MC_budget = MC_budget_exp,include_one_step = True,\n",
    "                                                                penalty = orthogonality_penalty_parameter_exp, rel_gap = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rollout with batch design\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_RB,DET_RB,HITRATE_RB,MSE_RB,Prob_sel_RB,true_partworths_RB,MU_RB] = new_sequential_experiment(bayes_expectation_exp,bayes_covariance_exp,partworths_exp,rep_per_partworth_exp,num_questions_exp,\n",
    "                                           look_ahead_horizon_exp,mu_log_exp,Sig_log_exp,noise_par_exp,question_list_exp,Method = 1,\n",
    "                                            batch_size = batch_size_exp,MC_budget = MC_budget_exp,include_one_step = True,\n",
    "                                                                penalty = orthogonality_penalty_parameter_exp, rel_gap = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only do two_step when there are 6 attributes.\n",
    "if attr_exp == 1:\n",
    "    #TWOSTEP via Enumeration\n",
    "    #Set up random number seed\n",
    "    rng = np.random.default_rng(100) \n",
    "    np.random.seed(100)\n",
    "    random.seed(100)\n",
    "\n",
    "    [Norm_MSE_TS,DET_TS,HITRATE_TS,MSE_TS,Prob_sel_TS,true_partworths_TS,MU_TS] = new_sequential_experiment(bayes_expectation_exp,bayes_covariance_exp,partworths_exp,rep_per_partworth_exp,num_questions_exp,\n",
    "                                               look_ahead_horizon_exp,mu_log_exp,Sig_log_exp,noise_par_exp,question_list_exp,Method = 2,\n",
    "                                                batch_size = batch_size_exp,MC_budget = MC_budget_exp,include_one_step = True,\n",
    "                                                                    penalty = orthogonality_penalty_parameter_exp, rel_gap = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2648eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rollout with coordinate exchange\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_RC,DET_RC,HITRATE_RC,MSE_RC,Prob_sel_RC,true_partworths_RC,MU_RC] = new_sequential_experiment(bayes_expectation_exp,bayes_covariance_exp,partworths_exp,rep_per_partworth_exp,num_questions_exp,\n",
    "                                           look_ahead_horizon_exp,mu_log_exp,Sig_log_exp,noise_par_exp,question_list_exp,Method = 3,\n",
    "                                            batch_size = batch_size_exp,MC_budget = MC_budget_exp,include_one_step = True,\n",
    "                                                                penalty = orthogonality_penalty_parameter_exp, rel_gap = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf376763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the columns of the dataframe.\n",
    "\n",
    "#Collect the data above into one list. Note that we will not have two step when there are 12 attributes due to enumeration\n",
    "#taking too long.\n",
    "if attr_exp == 1:\n",
    "    data_collection = [[Norm_MSE_OS,DET_OS,HITRATE_OS,MSE_OS,Prob_sel_OS,true_partworths_OS,MU_OS],[Norm_MSE_RB,DET_RB,HITRATE_RB,MSE_RB,Prob_sel_RB,true_partworths_RB,MU_RB],\n",
    "                       [Norm_MSE_TS,DET_TS,HITRATE_TS,MSE_TS,Prob_sel_TS,true_partworths_TS,MU_TS],[Norm_MSE_RC,DET_RC,HITRATE_RC,MSE_RC,Prob_sel_RC,true_partworths_RC,MU_RC]]\n",
    "    method_range = 4\n",
    "\n",
    "if attr_exp == 2:\n",
    "    data_collection = [[Norm_MSE_OS,DET_OS,HITRATE_OS,MSE_OS,Prob_sel_OS,true_partworths_OS,MU_OS],[Norm_MSE_RB,DET_RB,HITRATE_RB,MSE_RB,Prob_sel_RB,true_partworths_RB,MU_RB],\n",
    "                       [Norm_MSE_RC,DET_RC,HITRATE_RC,MSE_RC,Prob_sel_RC,true_partworths_RC,MU_RC]]\n",
    "    method_range = 3\n",
    "\n",
    "Norm_MSE_col = []\n",
    "DET_col = []\n",
    "MSE_col = []\n",
    "HITRATE_col = []\n",
    "Prob_sel_col = []\n",
    "Part_col = []\n",
    "Method_col = []\n",
    "\n",
    "rep_col = []\n",
    "quest_col = []\n",
    "\n",
    "#Columns here are the entries in the ith component of the true partworth and estimator mu\n",
    "true_partworths_col = [[] for i in range(attributes_exp)]\n",
    "MU_col = [[] for i in range(attributes_exp)]\n",
    "\n",
    "#Construct the Norm_MSE, DET, and MSE columns\n",
    "#Methods are 0=OS, 1=RB, 2=TS, 3=RC for 6 attributes. 0=OS, 1=RB, 2=RC for 12 attributes\n",
    "\n",
    "for Meth in range(method_range):\n",
    "    for part in range(100):\n",
    "        for r in range(rep_per_partworth_exp):\n",
    "            for q in range(num_questions_exp):\n",
    "                Norm_MSE_col.append(data_collection[Meth][0][part][q][r])\n",
    "                DET_col.append(data_collection[Meth][1][part][q][r])\n",
    "                MSE_col.append(data_collection[Meth][3][part][q][r])\n",
    "                \n",
    "                HITRATE_col.append(data_collection[Meth][2][part][r])\n",
    "                Prob_sel_col.append(data_collection[Meth][4][part])\n",
    "                \n",
    "                Method_col.append(Meth)\n",
    "                Part_col.append(part)\n",
    "                \n",
    "                rep_col.append(r + 1)\n",
    "                quest_col.append(q + 1)\n",
    "                \n",
    "                for i in range(attributes_exp):\n",
    "                    true_partworths_col[i].append(data_collection[Meth][5][part][i])\n",
    "                    MU_col[i].append(data_collection[Meth][6][part][q][r][i])\n",
    "\n",
    "#Data for the mu vector and true partworths\n",
    "df_columns_data = [Method_col,Part_col,rep_col,quest_col,Norm_MSE_col,DET_col,MSE_col,HITRATE_col,Prob_sel_col]\n",
    "\n",
    "for i in range(attributes_exp):\n",
    "    df_columns_data.append(MU_col[i])\n",
    "\n",
    "for i in range(attributes_exp):\n",
    "    df_columns_data.append(true_partworths_col[i])\n",
    "    \n",
    "df_columns_data = np.array(df_columns_data).T\n",
    "\n",
    "#Make column names\n",
    "df_columns_names = ['Method', 'Partworth','Rep','Question','Norm_MSE','Det','MSE','Hitrate','Prob. Sel']\n",
    "\n",
    "for i in range(attributes_exp):\n",
    "    df_columns_names.append('Mu_' + str(i+1))\n",
    "\n",
    "\n",
    "for i in range(attributes_exp):\n",
    "    df_columns_names.append('True_' + str(i+1))\n",
    "    \n",
    "#Make dataframe. The number of columns is 9 + 2*attributes. The number of rows is method_range*100*rep_per_partworth*num_questions\n",
    "#100 comes from the 100 true_partworths that we use.\n",
    "df_data = pd.DataFrame(data = df_columns_data, index = range(1,method_range*100*rep_per_partworth_exp*num_questions_exp + 1),\n",
    "                      columns = df_columns_names)\n",
    "#print(df_data)\n",
    "#df_data.to_csv(r'C:\\Users\\wsfishe\\Desktop\\df_data.csv',index=True,header=True)\n",
    "df_data.to_csv('\\sequential_data_TYPEII_attr_'+str(attr_exp)+ '_exp_'+str(bp_expect_exp)+'_cov_'+str(bp_cov_exp) +\n",
    "               '_snr_' + str(signal_noise_exp) + '_look_' + str(look_ahead_exp) + '_orth_' + str(ortho_pen_exp)+'.csv',\n",
    "               index=True,header=True)\n",
    "\n",
    "#print(df_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
